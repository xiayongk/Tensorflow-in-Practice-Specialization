{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1598856266776",
   "display_name": "Python 3.8.3 64-bit ('tf2.0-gpu': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "서브워드(subword) 분절 기법\n",
    "    - 하나의 단어는 의미있는 여러 내부 단어(subword)의 조합으로 구성된 경우가 많음\n",
    "    - ex) \"confidence\" > \"con\", \"f\", \"er\", \"ence\"\n",
    "    - 단어 분리 작업은 토크나이징 전처리 과정에서 많이 활용함\n",
    "    - 한국어, 일본어, 영어 등 언어에 구애받지 않고, 별도의 문법 없이 조사 구분이 가능함\n",
    "    - 장점\n",
    "        - OOV 문제에 대해 어느 정도 대처할 수 있도록 함\n",
    "        - 단어가 많아질수록 학습해야 할 양이 늘어나는데, 이를 줄일 수 있음\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "2.2.0\n"
    }
   ],
   "source": [
    "# NOTE: PLEASE MAKE SURE YOU ARE RUNNING THIS IN A PYTHON3 ENVIRONMENT\n",
    "\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "2.2.0\n"
    }
   ],
   "source": [
    "# Double check TF 2.0x is installed. If you ran the above block, there was a \n",
    "# 'reset all runtimes' button at the bottom that you needed to press\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "WARNING:absl:TFDS datasets with text encoding are deprecated and will be removed in a future version. Instead, you should use the plain text version and tokenize the text using `tensorflow_text` (See: https://www.tensorflow.org/tutorials/tensorflow_text/intro#tfdata_example)\n"
    }
   ],
   "source": [
    "# If the import fails, run this\n",
    "# !pip install -q tensorflow-datasets\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "imdb, info = tfds.load(\"imdb_reviews/subwords8k\", with_info=True, as_supervised=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = imdb['train'], imdb['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": ", 'pee', 'nar', 'location_', 'ining_', 'gam', 'disappointing_', 'desire_', 'criminal_', 'considera', 'century_', 'celebrat', 'brow', 'area', 'Thin', 'Rec', \"' (\", 'ward_', 'vision_', 'treme', 'surprising_', 'super_', 'risk', 'receive', 'qual', 'pic', 'mee', 'levels', 'kins', 'jack', 'ire_', 'introduc', 'hits_', 'happening_', 'handsome', 'gradua', 'giv', 'garbage', 'forces_', 'finest_', 'easi', 'depressing', 'credits', 'asto', 'Sadly', 'Ple', 'Inc', 'Dick_', 'Alexand', 'wooden_', 'wood_', 'stro', 'steal_', 'soul_', 'reference', 'race', 'quis', 'pir', 'perv', 'obvious', 'majority_', 'lean', 'kes_', 'insti', 'identity', 'everybody_', 'double_', 'dies', 'credit', 'const', 'confe', 'compar', 'centur', 'bloody_', 'Under', 'Twi', 'Sean_', 'Lio', 'Halloween', 'Gal', 'Clu', 'Came', 'Barbara_', '?)', '11_', 'ws', 'ulous', 'subtle', 'substance', 'string', 'shocking_', 'scientist_', 'rian', 'nou', 'multi', 'lf', 'inal', 'harsh', 'handed', 'fir', 'expectations_', 'excited', 'exceptional', 'eva', 'complete', 'comic', 'childhood_', 'ched_', 'adults_', 'Timo', 'Soo', 'Mos', 'Kath', 'Karl', 'Cinderella', 'Christian', 'Age', 'Adam', '!). ', 'zar', 'zan', 'trap', 'trai', 'thin_', 'site_', 'site', 'rich', 'resi', 'reach_', 'quirk', 'patr', 'ony', 'nerv', 'matche', 'inept', 'imagine', 'horri', 'front', 'ford_', 'epic_', 'dat', 'cynic', 'ckin', 'cie', 'caused_', 'brothers_', 'belo', 'appealing', 'West_', 'UK', 'TC', 'Suc', 'Rand', 'Grad', 'Domin', 'Disney', '12_', 'warr', 'vision', 'spoo', 'seeing', 'scenario', 'scale', 'rad', 'ola', 'next', 'necessary_', 'indicat', 'exploitation', 'ened_', 'directing', 'depict', 'curio', 'ciati', 'bullet', 'appre', 'amateurish', 'Yo', 'Watching_', 'Sky', 'Shar', 'Part_', 'Nichol', 'Mars', 'Are_', 'wel', 'visit_', 'unne', 'underrated', 'tedious', 'seconds_', 'rig', 'report', 'reme', 'rar', 'mond_', 'media_', 'lying_', 'las', 'language', 'ised_', 'instant', 'inspiration', 'creates_', 'conflict', 'compose', 'chan', 'cab', 'ava', 'always', 'Water', 'Steven_', 'Pas', 'Nick_', 'Let_', 'Down', 'yth', 'victims_', 'theaters', 'seasons', 'sai', 'rising', 'recr', 'plann', 'pent', 'painfully_', 'ot_', 'occu', 'nob', 'moti', 'lem', 'lati', 'gua', 'fights_', 'event_', 'elev', 'discovered_', 'cs', 'cliché_', 'cance', 'bik', 'bigger_', 'backs', 'atic', 'Shan', 'Sab', 'Poi', 'Hitchcock', 'GR', 'Francis', 'Det', 'Care', 'Anderson', 'veteran', 'ution_', 'theless', 'sports', 'slave', 'ses', 'revi', 'refreshing', 'quar', 'provok', 'premise', 'paper', 'nty', 'norm', 'mood', 'menac', 'loud', 'loose', 'letter', 'investigati', 'introduce', 'holes_', 'gan_', 'fund', 'ents_', 'drunk', 'disgusting', 'dio', 'confusing_', 'cky', 'baby', 'THE', 'Nancy', 'Kate_', 'Gia', 'Carol', 'Cand', \"'.\", 'western', 'unf', 'struc', 'strong', 'search', 'sav', 'ries_', 'resemble', 'rental', 'raci', 'producer', 'nic_', 'news_', 'memor', 'many', 'magical', 'format', 'equal', 'decl', 'curs', 'ction', 'convict', 'contrived', 'capable_', 'bringing_', 'boyfriend_', 'bli', 'anybody_', 'animal_', 'advertis', 'Music', 'Jun', 'Jones', 'Greg', 'Fra', 'Donald_', 'Dark', '1930', 'é_', 'yc', 'urne', 'tire', 'step', 'scr', 'reporter', 'position', 'okay', 'nted_', 'misse', 'logical', 'ient', 'identif', 'feet', 'fail_', 'creat', 'content_', 'contemp', 'concei', 'border', 'ask', 'actual', 'Way', 'Plus', 'Mill', 'Foo', 'Dy', 'Bec', ' ,', 'utter_', 'urban', 'struggle', 'sign_', 'sher', 'seduc', 'scientist', 'saw', 'released', 'received_', 'lity_', 'jump_', 'island_', 'ignor', 'ick', 'horrifi', 'hange', 'handled', 'endea', 'dil', 'ative', 'angry_', 'ages_', 'accus', 'Writ', 'Without_', 'Wall', 'Thank', 'Sla', 'Qua', 'Page', 'ND', 'Lost', 'Fish', 'Eric_', 'Does', 'Clau', 'Cel', 'Camp', 'Australian', 'Arn', 'Ann_', 'Ala', 'Actually', \".' \", \",' \", 'wall_', 'thoughts', 'somebody_', 'round', 'proud', 'oy', 'overly_', 'opera_', 'offensive', 'myth', 'murderer', 'mpt', 'ivi', 'ir_', 'iga', 'iar', 'holi', 'hearted_', 'gath', 'fictional', 'expectation', 'etta', 'enco', 'ence', 'deserved_', 'depiction', 'dece', 'comedian', 'bles', 'aside_', 'ambi', 'ake', 'Wonder', 'Why', 'Through', 'Overall_', 'Off', 'OI', 'More_', 'Jennifer_', 'Gill', 'Germany', 'Douglas_', 'Cy', 'CGI_', '\").', 'walks_', 'ury', 'three', 'thank_', 'surp', 'soph', 'sed', 'satisfying', 'rebel', 'pure', 'practically_', 'minds', 'manage', 'lp', 'learns_', 'isl', 'involves_', 'impro', 'impa', 'icon', 'hyp', 'fortune', 'erm', 'cuts_', 'copi', 'conclusion_', 'ced_', 'captured_', 'bble', 'arro', 'Wei', 'Sis', 'Pin', 'Marg', 'Life', 'Laur', 'Later', 'Hop', 'Eva', 'Blue', 'Barry', 'Baby', 'whilst_', 'unfa', 'twi', 'test_', 'ters', 'stric', 'streets', 'stom', 'spoil', 'relative', 'relate_', 'recommend', 'ology', 'middle', 'laughable', 'jea', 'genuine_', 'gat', 'frustrati', 'forth', 'excitement', 'costs', 'cord', 'compo', 'bright_', 'bank', 'aka', 'WE', 'Ten', 'THAT', 'Pur', 'Pitt', 'Mike_', 'Hum', 'Being_', 'veri', 'turi', 'tun', 'tel', 'task', 'sting', 'six', 'sentimental', 'quit', 'pleasure_', 'pity', 'personality_', 'motivation', 'moder', 'miserabl', 'mirror', 'manner_', 'logi', 'ein', 'eful', 'dubbed', 'discussi', 'ders', 'defeat', 'dangerous_', 'cry_', 'clos', 'cial_', 'chor', 'Wat', 'Wan', 'Spanish_', 'Have', 'Guy', 'Game', '. . ', 'winner', 'welcome', 'unexp', 'ture', 'tall', 'tal', 'stoo', 'smo', 'serious', 'rc', 'phi', 'outrage', 'oh', 'national_', 'mber_', 'mba', 'loser', 'lee', 'largely_', 'involve', 'ico', 'garbage_', 'found', 'even', 'distinct', 'design_', 'cure', 'consu', 'circumstances', 'calls_', 'blown_', 'attract', 'anime', 'Zi', 'Vietnam', 'Ryan', 'ON_', 'NY', 'Lady_', 'La_', 'Flor', 'Bern', 'AI', ' )', 'unk', 'unh', 'ugly_', 'tine', 'spre', 'simpli', 'significant', 'sequels', 'remembered_', 'reache', 'plat', 'obsessed_', 'ncy_', 'mysteri', 'mous', 'mbs', 'lover_', 'lights', 'lad', 'industr', 'ible', 'grown_', 'general', 'fru', 'explosion', 'exception', 'ese', 'endur', 'domina', 'dera', 'cies', 'built_', 'barr', 'Tod', 'Ran', 'Maria', 'Grand', 'Dee', 'Aw', ' />**', 'xo', 'voices', 'visually', 'ui', 'twice_', 'tend_', 'spor', 'solut', 'slap', 'scien', 'robbe', 'redibl', 'prot', 'prevent', 'ood', 'kee', 'issue_', 'ironic', 'iron', 'investigat', 'intr', 'hl', 'gus', 'food_', 'enl', 'dl', 'described_', 'complaint', 'careful', 'apartment_', 'alcohol', 'aid', 'acy', 'Year', 'Vis', 'Vir', 'Tow', 'Fly', 'Dream', 'Award', '*****', 'vague', 'strat', 'reviewers_', 'offend', 'locat', 'iu', 'ital', 'iev', 'hospital_', 'fou', 'financ', 'filmmaker_', 'farm', 'evening', 'essentially_', 'energy_', 'ef_', 'complex', 'competi', 'ching', 'bal_', 'ax', 'ances', 'acted', 'ace_', 'Story', 'LD', 'Inde', 'Hope', 'Duk', 'Dian', 'Bob', 'Back', 'Any_', 'About_', ' ...', 'yard', 'whenever_', 'wake', 'ures_', 'unse', 'trust_', 'treat_', 'teenager', 'stock_', 'rri', 'rise_', 'rant', 'pupp', 'pte', 'pes', 'overd', 'operati', 'occasional', 'nicely_', 'nical', 'liners', 'impo', 'holding_', 'engaging_', 'diver', 'distribut', 'dim', 'delightful_', 'crappy_', 'cook', 'connection_', 'cohe', 'bore', 'Vincen', 'Susan', 'Rep', 'Powell', 'Oliver', 'Neil', 'Murphy', 'Mic', 'Indi', 'Ele', 'Bru', 'Beaut', '. *', ' />*', 'zation', 'urge', 'urag', 'teenagers', 'seven_', 'river', 'prep', 'nail', 'mble_', 'matters', 'loose_', 'iva', 'issue', 'intriguing_', 'ili', 'god_', 'glimpse', 'ently', 'els_', 'een_', 'develop_', 'desire', 'cops_', 'contra', 'buil', 'broke', 'ater', 'asleep', 'adventur', 'Williams_', 'Wend', 'None_', 'Mod', 'House', 'Horror_', 'Anim', '192', 'ughter', 'trial', 'soap_', 'severe', 'road', 'poster', 'portraying_', 'phr', 'pathetic', 'overlook', 'moving', 'month', 'lau', 'lacking_', 'knowledge_', 'kidnapp', 'interpretation', 'industry_', 'hurt', 'heavi', 'genius', 'false', 'existent', 'execution', 'drop', 'difference', 'determine', 'detail_', 'dent', 'cutting', 'combin', 'comb', 'cket', 'chron', 'capital', 'bodies', 'bic', 'believes_', 'area_', 'angles', 'Ted', 'Sop', 'End', 'Dre', 'Dick', 'Ak', 'Africa', ' ? ', 'vol', 'system', 'steps', 'situations', 'sexuality', 'sets', 'ripp', 'revel', 'rel', 'realiz', 'private', 'paper_', 'notch', 'nge_', 'mistr', 'merit', 'mbl', 'match', 'losing_', 'lme', 'interacti', 'indeed', 'ifica', 'henc', 'heaven', 'fro', 'fon', 'femin', 'faces_', 'enh', 'driven_', 'dressed_', 'dne', 'decen', 'ctic', 'coming', 'club_', 'castle', 'captures_', 'building', 'atic_', 'athe', 'assassin', 'army_', 'alien_', 'abso', 'Tho', 'Scr', 'Prob', 'Para', 'Gor', 'Eg', 'Com', 'City', 'At', 'Apparently', ' / ', 'ule', 'ue_', 'tograph', 'thirt', 'thank', 'suit_', 'suffering_', 'sight_', 'sey', 'screenwriter', 'rell', 'ppet', 'passed_', 'pacing_', 'normally_', 'mill', 'lyn', 'ition', 'gers', 'football', 'faithful', 'expose', 'expos', 'emerge', 'ell_', 'depicted', 'crude', 'criticism', 'combination_', 'claim_', 'carr', 'bt', 'brilliantly_', 'boss', 'analy', 'ame', 'Ray', 'Pic', 'Lord_', 'Kill', 'Fea', 'Evil', 'Bos', 'BS', 'AB', '\" - ', ' :', 'tta', 'trailer', 'soli', 'rum', 'revolve', 'ressi', 'quiet_', 'portrays_', 'populat', 'plant', 'oin', 'occasionally_', 'nost', 'nau', 'mun', 'lb', 'ipat', 'hysteri', 'grow_', 'gag', 'fus', 'foot_', 'finger', 'figur', 'esp', 'equi', 'ener', 'dec', 'chain', 'broken_', 'agent', 'actions_', 'aa', 'Russell', 'Indian', 'Heav', 'Daniel_', 'Ast', ' /> ', 'zard', 'unlikely', 'ump', 'tele', 'teacher_', 'subplot', 'rub', 'rte', 'rly_', 'radio_', 'quir', 'pair_', 'ordinary_', 'oppos', 'nsi', 'mouth_', 'maintain', 'lve', 'loc', 'inventi', 'inexp', 'imitat', 'generate', 'gal_', 'frightening', 'frig', 'foreign_', 'filmmaker', 'excess', 'elle', 'creator', 'count_', 'controvers', 'cliche', 'casti', 'bet_', 'aking_', 'acqu', 'Three', 'Texas', 'Tarzan_', 'Earth_', 'Dan_', 'Besides', 'yw', 'woods_', 'wan', 'vest', 'uous', 'unit', 'therefore_', 'tears_', 'surface', 'steals_', 'sni', 'shut', 'roman', 'roll_', 'rele', 'reaction', 'qualities', 'proper_', 'profession', 'photo', 'months_', 'mem', 'makeup', 'longe', 'lam', 'ix', 'insist', 'inher', 'fying_', 'forgettable', 'faced', 'expens', 'enthusias', 'describ', 'cry', 'commentary_', 'collection_', 'civili', 'category', 'cam', 'believed', 'ancient_', 'Walter_', 'Sum', 'Sometimes', 'Sel', 'Lou', 'Kn', 'Joseph_', 'Gro', 'Fon', 'Columbo', 'system_', 'student', 'shocked', 'sell_', 'ridi', 'prior', 'primar', 'mon_', 'mmer', 'lish', 'higher_', 'fatal', 'employe', 'dirty', 'cris', 'conf', 'ckle', 'blend', 'bility_', 'baseball', 'awake', 'arr', 'ape', 'alive_', 'Wid', 'Santa_', 'Kei', 'Dep', 'Burn', 'Bob_', '´', 'warn', 'unknown_', 'twenty_', 'touches', 'supernatural', 'sitcom', 'saving_', 'rupt', 'relatively_', 'possibilit', 'nose', 'mes_', 'massive', 'male', 'ied', 'honor', 'heroes_', 'gig', 'gangs', 'divi', 'diat', 'consequen', 'classics', 'cases', 'bug', 'brief', 'bott', 'assume_', 'associate', 'assistan', 'arra', 'aria', 'absen', 'VHS_', 'Steve', 'Port', 'Paris', 'Old_', 'Morgan_', 'Horr', 'High_', 'General', 'Din', 'Dark_', 'Colo', 'Avoid_', 'zel', 'unnecessary_', 'unexpected_', 'tragedy_', 'tim', 'stle', 'stereo', 'stai', 'send_', 'recommended_', 'produce', 'pregnan', 'noon', 'move', 'ludicrous', 'lude', 'length', 'ident_', 'ide_', 'grue', 'focused', 'extraordinar', 'desperate', 'depress', 'dai', 'creature_', 'covered_', 'chief', 'boss_', 'asking_', 'Yeah', 'WW', 'Rid', 'Island', 'FA', 'Denn', 'Ch', 'Basically', 'Ang', 'Ami', '?! ', '): ', 'virtually_', 'underg', 'truck', 'training', 'tif', 'surf', 'rmin', 'reject', 'rante', 'plots_', 'placed_', 'ni_', 'mature', 'lousy_', 'justice_', 'io_', 'glori', 'gentle', 'fly_', 'explanation_', 'execut', 'exaggerat', 'events', 'elie', 'destructi', 'choose_', 'characteriz', 'char', 'cent_', 'books', 'bby', 'appreciated', 'allo', 'Neve', 'Nee', 'Jackson_', 'Irish', 'IN_', 'During_', 'Devil', 'Count', 'yes_', 'user', 'unpr', 'tual', 'treasure', 'stronge', 'sorr', 'ruined_', 'reputation', 'rently', 'related', 'quel', 'produce_', 'presum', 'politics', 'plans', 'painting', 'killers', 'initial_', 'impli', 'ify', 'hooke', 'funnie', 'fad', 'empty_', 'driver', 'di_', 'detect', 'designed', 'deserve', 'believ', 'awesome', 'accents', 'Your', 'Thank_', 'RE_', 'Pacino', 'Movies', 'Jay', 'IMDb', 'Hugh', 'Festival', 'Enter', 'Donn', 'Christi', 'Alm', 'Academy_', '000_', 'ycl', 'vivi', 'upset', 'ups_', 'unp', 'tiny', 'surprises', 'study_', 'strongly_', 'speaks', 'size', 'riv', 'relation', 'quee', 'py', 'never', 'mainstream', 'libera', 'latest', 'ising', 'insu', 'icia', 'hurt_', 'freedom', 'estl', 'emotionally_', 'dust', 'desc', 'convinced_', 'compell', 'cock', 'clothes_', 'cameo_', 'blind_', 'besides', 'attacke', 'Victor_', 'Return', 'Poo', 'Never_', 'Nel', 'Hey', 'Caine', 'Brando', 'ually_', 'tive', 'silen', 'rew', 'quate', 'preach', 'ological', 'nude', 'multiple', 'link', 'lge', 'ledge', 'laz', 'integr', 'hn', 'hie', 'folks_', 'experiences', 'emphasi', 'earlier', 'delivered_', 'deco', 'deaths', 'continuity', 'complicate', 'burne', 'boyfriend', 'awkward_', 'atrocious', 'amuse', 'ack_', 'Wilson', 'Turn', 'Robin_', 'Pr', 'Om', 'Mun', 'Meanwhile', 'Jessi', 'Jess', 'Jenn', 'Gand', 'Et', 'Canadian_', 'Brothers', 'Bake', 'Ah', '1990', 'wreck', 'unif', 'toi', 'teens', 'smart', 'shir', 'serves_', 'sati', 'rix', 'remain_', 'pub', 'propaganda', 'players_', 'plas', 'ping', 'overcom', 'orious', 'minde', 'meeting_', 'lph', 'loyal', 'lm', 'llin', 'lake', 'kar', 'istic', 'instru', 'included_', 'hire', 'graph', 'gory_', 'favour', 'elde', 'dum', 'destroy_', 'destin', 'denti', 'consistent', 'cameo', 'betr', 'arrest', 'appea', 'animal', 'amen', 'accidentally', 'acce', 'Silv', 'Saturday_', 'ST_', 'Res', 'MGM', 'Korea', 'Fam', 'Asian_', 'Alle', 'zu', 'weeks', 'ticke', 'terrifi', 'table_', 'storytell', 'stopped_', 'steal', 'slash', 'shoe', 'select', 'rocke', 'roa', 'record_', 'previously', 'participa', 'okay_', 'ogr', 'official', 'nke', 'mistakes', 'misca', 'memorabl', 'logue', 'itat', 'ists_', 'intelligence_', 'ien', 'greate', 'ggy', 'gangster_', 'critical', 'closer', 'cartoons', 'boot', 'accepta', 'abu', 'TER', 'States', 'Roberts', 'LER', 'Jones_', 'Hat', 'Eri', 'Eliza', 'Coop', 'wes', 'uninteresting', 'tense', 'teet', 'suffers_', 'stranger', 'station_', 'scu', 'resid', 'rand', 'popula', 'ours', 'opene', 'occurr', 'non_', 'nominated_', 'mol', 'missi', 'memory_', 'memories_', 'maid', 'intri', 'inju', 'inevitabl', 'humans_', 'hanging_', 'gratuitous_', 'gas_', 'forme', 'direct', 'difficult', 'department', 'damag', 'creatures', 'cif', 'Warner', 'Titan', 'Matt_', 'Larr', 'KI', 'Hor', 'Holm', 'Fair', 'Drew', 'Andr', '1960', 'wri', 'vely', 'uls', 'travel_', 'trat', 'transf', 'timi', 'suspen', 'struggling', 'spoil_', 'slaps', 'sink', 'reti', 'reaction_', 'quest_', 'pilot_', 'narration', 'invite', 'hearing_', 'gm', 'gai', 'full', 'frankly', 'fairy', 'expe', 'dimension', 'dent_', 'deme', 'contest', 'conscious', 'cked', 'below_', 'ations', 'angel', 'alive', 'absurd_', 'Wer', 'Tha', 'Stewar', 'Play', 'Picture', 'Part', 'Martin', 'Franc', 'Fir', 'Fas', 'Ev', 'Cos', 'Carre', 'Bog', 'BU', 'Anne_', 'yan', 'writ', 'vit', 'vai', 'summ', 'ston', 'stin', 'stif', 'sensitive', 'rules', 'provided_', 'prostitut', 'pretentious_', 'poignan', 'pai', 'paced_', 'offi', 'nds_', 'mig', 'laughable_', 'instal', 'inati', 'forget', 'eit', 'defend', 'conse', 'beaut', 'Spr', 'Rol', 'Our_', 'NOT', 'Lugosi', 'Luci', 'Las', 'Imp', 'Ic', 'Earl', 'Davis_', 'Cod', '!)', 'twiste', 'sincer', 'sacrifice', 'references_', 'range_', 'purchase', 'orn', 'noise', 'neo', 'mecha', 'lun', 'insult_', 'fully', 'flicks_', 'fair', 'endless_', 'eeri', 'devot', 'curious_', 'comical', 'beth_', 'begin', 'aura', 'ase_', 'ach_', 'Sullivan', 'St', 'Sarah', 'London', 'Liv', 'Kee', 'Jackie_', 'Hong', 'Emil', 'Clair', 'China', 'California', 'Atlant', 'Alice', '\"?', '!!!!!!', 'xico', 'wick', 'visi', 'viewed_', 'uish', 'tribu', 'theatrical_', 'talks_', 'smile_', 'seven', 'reminisce', 'relie', 'rci', 'rah', 'pleasant_', 'plague', 'picio', 'ounce', 'murdered_', 'mul', 'mous_', 'mock', 'mira', 'mete', 'loss_', 'initia', 'iest_', 'health', 'harde', 'gran', 'goal', 'ghe', 'fy', 'fix', 'experienced', 'edy', 'deci', 'conflict_', 'compe', 'committed', 'cele', 'brick', 'bour', 'bers', 'berate', 'artist_', 'anth', 'Woody_', 'WWI', 'V_', 'TT', 'Sunday', 'Story_', 'Rob_', 'Rachel', 'Nin', 'Gree', 'Friday', 'Dev', 'Bros', 'Brana', ' : ', 'wha', 'vig', 'views', 'unconvincing', 'smi', 'sibl', 'quen', 'pointless', 'perp', 'particular', 'overwhelm', 'offered', 'nominat', 'naturally', 'locke', 'left', 'lady', 'ilt', 'iel', 'ication', 'historic', 'haunting', 'gem_', 'figures', 'figured_', 'evol', 'ery', 'eco', 'dynami', 'duct', 'doi', 'description', 'cultural', 'contrac', 'confide', 'combined', 'coin', 'cke', 'chosen_', 'amed', 'agon', 'Thomas_', 'THI', 'Nation', 'MOVIE', 'Lev', 'Jeff', 'Hoffman', 'Glen', 'Even', '1st_', ' ! ', 'yu', 'trappe', 'thir', 'tension', 'tail', 'table', 'split', 'sides', 'settle', 'schem', 'save', 'ruc', 'prime', 'posit', 'painte', 'ndi', 'marry_', 'kun', 'killing', 'isol', 'iot', 'intend', 'impres', 'horribly_', 'hing', 'heroi', 'gle_', 'fri', 'fitt', 'fighter', 'estin', 'ee_', 'drunk_', 'directly', 'dinos', 'chose_', 'changing', 'blonde_', 'benefi', 'award_', 'av', 'aki', 'ages', 'acter', 'VERY_', 'Ur', 'Tel', 'Superman_', 'Real', 'Phi', 'Palm', 'Nicol', 'Johnson', 'Jesus_', 'J_', 'Hes', 'Helen', 'Fun', 'Fle', 'Dir', 'Chap', 'vag', 'uncon', 'ues', 'types_', 'tical', 'sprin', 'sorts', 'securi', 'previ', 'porno', 'party', 'pare', 'method', 'medica', 'mber', 'landscape', 'jor', 'jail', 'imper', 'hunter', 'happening', 'gritty', 'gain_', 'flaws_', 'fak', 'extra', 'edited_', 'ecc', 'dragg', 'chie', 'cant_', 'breast', 'authorit', 'ated', 'ality', 'advise', 'advan', 'according_', 'Wors', 'Unlike', 'United_', 'Simon_', 'Riv', 'Pea', 'Michell', 'Exp', 'Child', 'Cham', 'Bourne', 'Basi', 'widow', 'walked_', 'upp', 'unforg', 'uld_', 'tting', 'till_', 'thy_', 'talents_', 'suspenseful', 'summer_', 'storm', 'screening', 'scare_', 'realizes_', 'rce', 'raw', 'qu', 'ngl', 'magic', 'lac', 'jobs', 'ister_', 'inti', 'inha', 'ill_', 'hands', 'grin', 'forward', 'examin', 'equent', 'emi', 'contact', 'concentrat', 'compu', 'competen', 'biograph', 'attach', 'amus', 'alik', 'activi', 'William', 'Myst', 'Luke_', 'Live', 'Life_', '15', 'zes', 'werewolf', 'warne', 'uring_', 'trilogy', 'swim', 'stumble', 'spite', 'spends_', 'sleep_', 'sist', 'sentence', 'rma', 'reward', 'reviewer_', 'pul', 'preten', 'performed', 'passing', 'par_', 'oph', 'livi', 'kinds_', 'journal', 'isticat', 'inva', 'idi', 'ham_', 'fte', 'few', 'featured', 'ern_', 'eag', 'dollars', 'disb', 'depth', 'cryin', 'cross_', 'content', 'contemporary_', 'colors', 'chee', 'because', 'asy', 'agent_', 'Willi', 'Warr', 'Ven', 'Vamp', 'Roch', 'ONE', 'Movie', 'Mau', 'Mass', 'MST', 'Hin', 'Hear', 'Gue', 'Gl', 'Freddy_', 'Definite', 'Captain_', 'BBC', '??? ', '80s_', '\"), ', 'wol', 'weekend', 'vampires', 'underst', 'tial_', 'terrorist', 'strength_', 'starre', 'soldier_', 'snow', 'sity', 'ruin_', 'retar', 'resu', 'required', 'recommended', 'ques', 'propo', 'presents_', 'perm', 'overt', 'olds', 'occas', 'nn_', 'nen', 'nei', 'mail', 'lost', 'lion', 'libr', 'inner_', 'headed', 'happy', 'guest', 'govern', 'friendly', 'explains', 'ens_', 'effectively', 'draw_', 'downright', 'dete', 'dde', 'dare', 'cring', 'courag', 'conspi', 'comedie', 'claims_', 'cide', 'chas', 'captivat', 'bite', 'bare', 'author_', 'addition', 'Vid', 'Rh', 'Oliv', 'Nata', 'Mexican', 'Keaton_', 'Iron', 'Barb', 'ALL_', '12', '!), ', 'worthwhile', 'weake', 'ung', 'understood_', 'unbelievable', 'superf', 'stolen', 'stereotypic', 'spoiler', 'sight', 'scares', 'rut', 'remove', 'remotely_', 'releva', 'prese', 'poke', 'ndou', 'mbla', 'lucky_', 'lling_', 'legendary', 'imagery', 'humou', 'hug', 'hired', 'heck', 'guilty', 'extras', 'expected', 'everywhere', 'dry_', 'drea', 'directed', 'dimensional_', 'ddi', 'dden', 'communica', 'cham', 'buddy', 'bank_', 'azi', 'algi', 'adventures', 'accurate_', 'accompan', 'Thom', 'Still_', 'Someone', 'Serious', 'SU', 'Phill', 'Perso', 'Patrick_', 'Lei', 'Jus', 'Gho', 'Get_', 'Freeman', 'Especially_', '?).', '...\"']\n"
    }
   ],
   "source": [
    "tokenizer = info.features['text'].encoder\n",
    "print(tokenizer.subwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Tokenized string is [6307, 2327, 4043, 2120, 2, 48, 4249, 4429, 7, 2652, 8050]\nThe original string: TensorFlow, from basics to mastery\n"
    }
   ],
   "source": [
    "sample_string = 'TensorFlow, from basics to mastery'\n",
    "\n",
    "tokenized_string = tokenizer.encode(sample_string)\n",
    "print ('Tokenized string is {}'.format(tokenized_string))\n",
    "\n",
    "original_string = tokenizer.decode(tokenized_string)\n",
    "print ('The original string: {}'.format(original_string))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "6307 ----> Ten\n2327 ----> sor\n4043 ----> Fl\n2120 ----> ow\n2 ----> , \n48 ----> from \n4249 ----> basi\n4429 ----> cs \n7 ----> to \n2652 ----> master\n8050 ----> y\n"
    }
   ],
   "source": [
    "for ts in tokenized_string:\n",
    "  print ('{} ----> {}'.format(ts, tokenizer.decode([ts])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 10000\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "train_dataset = train_data.shuffle(BUFFER_SIZE)\n",
    "train_dataset = train_dataset.padded_batch(BATCH_SIZE, tf.compat.v1.data.get_output_shapes(train_dataset))\n",
    "test_dataset = test_data.padded_batch(BATCH_SIZE, tf.compat.v1.data.get_output_shapes(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding (Embedding)        (None, None, 64)          523840    \n_________________________________________________________________\nglobal_average_pooling1d (Gl (None, 64)                0         \n_________________________________________________________________\ndense (Dense)                (None, 6)                 390       \n_________________________________________________________________\ndense_1 (Dense)              (None, 1)                 7         \n=================================================================\nTotal params: 524,237\nTrainable params: 524,237\nNon-trainable params: 0\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "embedding_dim = 64\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(tokenizer.vocab_size, embedding_dim),\n",
    "    tf.keras.layers.GlobalAveragePooling1D(), # Flatten()은 에러 발생(None 때문)\n",
    "    tf.keras.layers.Dense(6, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch 1/10\n"
    },
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "in user code:\n\n    C:\\Users\\hykim\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf2.0-gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:571 train_function  *\n        outputs = self.distribute_strategy.run(\n    C:\\Users\\hykim\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf2.0-gpu\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:951 run  **\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Users\\hykim\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf2.0-gpu\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2290 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\Users\\hykim\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf2.0-gpu\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2649 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\Users\\hykim\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf2.0-gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:532 train_step  **\n        loss = self.compiled_loss(\n    C:\\Users\\hykim\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf2.0-gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\compile_utils.py:205 __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    C:\\Users\\hykim\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf2.0-gpu\\lib\\site-packages\\tensorflow\\python\\keras\\losses.py:143 __call__\n        losses = self.call(y_true, y_pred)\n    C:\\Users\\hykim\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf2.0-gpu\\lib\\site-packages\\tensorflow\\python\\keras\\losses.py:246 call\n        return self.fn(y_true, y_pred, **self._fn_kwargs)\n    C:\\Users\\hykim\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf2.0-gpu\\lib\\site-packages\\tensorflow\\python\\keras\\losses.py:1595 binary_crossentropy\n        K.binary_crossentropy(y_true, y_pred, from_logits=from_logits), axis=-1)\n    C:\\Users\\hykim\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf2.0-gpu\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py:4692 binary_crossentropy\n        return nn.sigmoid_cross_entropy_with_logits(labels=target, logits=output)\n    C:\\Users\\hykim\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf2.0-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:171 sigmoid_cross_entropy_with_logits\n        raise ValueError(\"logits and labels must have the same shape (%s vs %s)\" %\n\n    ValueError: logits and labels must have the same shape ((None, 1) vs ())\n",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-76686cfd850b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'binary_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'adam'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf2.0-gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     64\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf2.0-gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 848\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    849\u001b[0m               \u001b[1;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    850\u001b[0m               \u001b[1;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf2.0-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    579\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 580\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    581\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    582\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf2.0-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    625\u001b[0m       \u001b[1;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    626\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 627\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    628\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    629\u001b[0m       \u001b[1;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf2.0-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[1;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[0;32m    503\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_deleter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFunctionDeleter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lifted_initializer_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    504\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m--> 505\u001b[1;33m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m    506\u001b[0m             *args, **kwds))\n\u001b[0;32m    507\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf2.0-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2444\u001b[0m       \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2445\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2446\u001b[1;33m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2447\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2448\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf2.0-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   2775\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2776\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2777\u001b[1;33m       \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2778\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2779\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf2.0-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   2655\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2656\u001b[0m     graph_function = ConcreteFunction(\n\u001b[1;32m-> 2657\u001b[1;33m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[0;32m   2658\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2659\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf2.0-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m    979\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    980\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 981\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    982\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    983\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf2.0-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    439\u001b[0m         \u001b[1;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    440\u001b[0m         \u001b[1;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 441\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    442\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mref\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    443\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf2.0-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    966\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    967\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 968\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    969\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    970\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    C:\\Users\\hykim\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf2.0-gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:571 train_function  *\n        outputs = self.distribute_strategy.run(\n    C:\\Users\\hykim\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf2.0-gpu\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:951 run  **\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Users\\hykim\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf2.0-gpu\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2290 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\Users\\hykim\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf2.0-gpu\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2649 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\Users\\hykim\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf2.0-gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:532 train_step  **\n        loss = self.compiled_loss(\n    C:\\Users\\hykim\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf2.0-gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\compile_utils.py:205 __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    C:\\Users\\hykim\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf2.0-gpu\\lib\\site-packages\\tensorflow\\python\\keras\\losses.py:143 __call__\n        losses = self.call(y_true, y_pred)\n    C:\\Users\\hykim\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf2.0-gpu\\lib\\site-packages\\tensorflow\\python\\keras\\losses.py:246 call\n        return self.fn(y_true, y_pred, **self._fn_kwargs)\n    C:\\Users\\hykim\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf2.0-gpu\\lib\\site-packages\\tensorflow\\python\\keras\\losses.py:1595 binary_crossentropy\n        K.binary_crossentropy(y_true, y_pred, from_logits=from_logits), axis=-1)\n    C:\\Users\\hykim\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf2.0-gpu\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py:4692 binary_crossentropy\n        return nn.sigmoid_cross_entropy_with_logits(labels=target, logits=output)\n    C:\\Users\\hykim\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf2.0-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:171 sigmoid_cross_entropy_with_logits\n        raise ValueError(\"logits and labels must have the same shape (%s vs %s)\" %\n\n    ValueError: logits and labels must have the same shape ((None, 1) vs ())\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_data, epochs=num_epochs, validation_data=test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_graphs(history, string):\n",
    "  plt.plot(history.history[string])\n",
    "  plt.plot(history.history['val_'+string])\n",
    "  plt.xlabel(\"Epochs\")\n",
    "  plt.ylabel(string)\n",
    "  plt.legend([string, 'val_'+string])\n",
    "  plt.show()\n",
    "  \n",
    "plot_graphs(history, \"accuracy\")\n",
    "plot_graphs(history, \"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = model.layers[0]\n",
    "weights = e.get_weights()[0]\n",
    "print(weights.shape) # shape: (vocab_size, embedding_dim)\n",
    "\n",
    "import io\n",
    "\n",
    "out_v = io.open('vecs.tsv', 'w', encoding='utf-8')\n",
    "out_m = io.open('meta.tsv', 'w', encoding='utf-8')\n",
    "for word_num in range(1, tokenizer.vocab_size):\n",
    "  word = tokenizer.decode([word_num])\n",
    "  embeddings = weights[word_num]\n",
    "  out_m.write(word + \"\\n\")\n",
    "  out_v.write('\\t'.join([str(x) for x in embeddings]) + \"\\n\")\n",
    "out_v.close()\n",
    "out_m.close()\n",
    "\n",
    "\n",
    "try:\n",
    "  from google.colab import files\n",
    "except ImportError:\n",
    "  pass\n",
    "else:\n",
    "  files.download('vecs.tsv')\n",
    "  files.download('meta.tsv')"
   ]
  }
 ]
}